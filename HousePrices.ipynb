{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# House prices regression\n",
    "- here you can read the Medium blogpost with more explanations -> \n",
    "- this is my kaggle profile ->  https://www.kaggle.com/dorianb96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Read the data\n",
    "- drop the id column for training data, but remember it for the test data\n",
    "- extract the label (house price) and transform it to log space\n",
    "- join the training and testing data into a single dataframe for easier transformation with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Rec</td>\n",
       "      <td>468</td>\n",
       "      <td>LwQ</td>\n",
       "      <td>144</td>\n",
       "      <td>270</td>\n",
       "      <td>882</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1961</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>108</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>923</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>406</td>\n",
       "      <td>1329</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1958</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1</td>\n",
       "      <td>312</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>393</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0          20       RH           80    11622   Pave   NaN      Reg   \n",
       "1          20       RL           81    14267   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl        NAmes      Feedr   \n",
       "1         Lvl    AllPub    Corner       Gtl        NAmes       Norm   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       Norm     1Fam     1Story            5            6       1961   \n",
       "1       Norm     1Fam     1Story            6            6       1958   \n",
       "\n",
       "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0          1961     Gable  CompShg     VinylSd     VinylSd       None   \n",
       "1          1958       Hip  CompShg     Wd Sdng     Wd Sdng    BrkFace   \n",
       "\n",
       "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "0           0        TA        TA     CBlock       TA       TA           No   \n",
       "1         108        TA        TA     CBlock       TA       TA           No   \n",
       "\n",
       "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          Rec         468          LwQ         144        270          882   \n",
       "1          ALQ         923          Unf           0        406         1329   \n",
       "\n",
       "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0    GasA        TA          Y      SBrkr       896         0             0   \n",
       "1    GasA        TA          Y      SBrkr      1329         0             0   \n",
       "\n",
       "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0        896             0             0         1         0             2   \n",
       "1       1329             0             0         1         1             3   \n",
       "\n",
       "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "0             1          TA             5        Typ           0         NaN   \n",
       "1             1          Gd             6        Typ           0         NaN   \n",
       "\n",
       "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0     Attchd         1961          Unf           1         730         TA   \n",
       "1     Attchd         1958          Unf           1         312         TA   \n",
       "\n",
       "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0         TA          Y         140            0              0          0   \n",
       "1         TA          Y         393           36              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea PoolQC  Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0          120         0    NaN  MnPrv         NaN        0       6    2010   \n",
       "1            0         0    NaN    NaN        Gar2    12500       6    2010   \n",
       "\n",
       "  SaleType SaleCondition  \n",
       "0       WD        Normal  \n",
       "1       WD        Normal  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data \n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# get the training data\n",
    "x_train_raw = train_data.drop(['Id','SalePrice'],axis=1)\n",
    "x_test_raw = test_data.drop('Id',axis=1)\n",
    "\n",
    "\n",
    "# remember the lenghts so we can split the data later\n",
    "train_length = len(x_train_raw)\n",
    "test_length = len(x_test_raw)\n",
    "\n",
    "# concatenate all of the training data into one dataframe so that transformations are easier\n",
    "all_data = pd.concat([x_train_raw, x_test_raw])\n",
    "\n",
    "\n",
    "# remember the test data indices only for the final submission \n",
    "x_test_ids = test_data['Id']\n",
    "\n",
    "# get the training data - house prices\n",
    "# normal prices have a skew so adjust them to log space\n",
    "y_train = np.log(train_data['SalePrice'])\n",
    "\n",
    "\n",
    "#display the data\n",
    "pd.set_option('display.max_columns', 500)\n",
    "x_test_raw.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Transforming features \n",
    "- missing -> encode \n",
    "- categorical -> One hot encoding\n",
    "- numerical -> scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a nice trick to find out numeric vs categorical features\n",
    "numerical_features = x_train_raw.columns[x_train_raw.dtypes != 'object']\n",
    "categorical_features = x_train_raw.columns[x_train_raw.dtypes == 'object']\n",
    "\n",
    "# encode missing numbers as a special large number\n",
    "all_data[numerical_features] = all_data[numerical_features].fillna(99999999)\n",
    "\n",
    "# encode missing data as a special category -> missing\n",
    "all_data[categorical_features] = all_data[categorical_features].fillna(\"Missing\")\n",
    "\n",
    "all_data.head(2)\n",
    "\n",
    "# transform numeric variables \n",
    "ss = StandardScaler()\n",
    "all_data[numerical_features] = ss.fit_transform(all_data[numerical_features])\n",
    "\n",
    "# transform categorical variables\n",
    "all_data = pd.get_dummies(data=all_data, columns=categorical_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-split the data back to original proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw features vs features in transformed model: 79 vs 311 features\n"
     ]
    }
   ],
   "source": [
    "# re-split again\n",
    "x_train = all_data.head(train_length)\n",
    "x_test = all_data.tail(test_length)\n",
    "\n",
    "print(\"Raw features vs features in transformed model:\", x_train_raw.shape[1] ,'vs', x_train.shape[1], 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.05, loss='huber', max_depth=3,\n",
       "             max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=15,\n",
       "             min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=2000, presort='auto', random_state=13,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = GradientBoostingRegressor(n_estimators=2000, learning_rate=0.05, max_depth=3, \n",
    "                                max_features='sqrt',min_samples_leaf=15, min_samples_split=10, \n",
    "                                loss='huber',random_state = 13)\n",
    "est.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Write the submission \n",
    "    - you should be able to get around 0.12104 score which would place you into top 1/3 of the scores (~685/2300+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_test = np.exp(est.predict(x_test))\n",
    "result = pd.DataFrame({'Id': x_test_ids.tolist(), 'SalePrice': y_test.ravel()})\n",
    "result.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Regressors  feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\n\\nfeature_importance = est.feature_importances_\\n# make importances relative to max importance\\nfeature_importance = 100.0 * (feature_importance / feature_importance.max())\\nsorted_idx = np.argsort(feature_importance)\\npos = (np.arange(sorted_idx.shape[0]) + .5 )[-20:]\\nfig = plt.figure(figsize=(25,10))\\nax = fig.add_subplot(111)\\nplt.barh(pos, feature_importance[sorted_idx][-20:], align='center')\\nplt.yticks(pos, x_train.columns[sorted_idx][-20:])\\nplt.xlabel('Relative Importance')\\nplt.title('Variable Importance')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "feature_importance = est.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = (np.arange(sorted_idx.shape[0]) + .5 )[-20:]\n",
    "fig = plt.figure(figsize=(25,10))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.barh(pos, feature_importance[sorted_idx][-20:], align='center')\n",
    "plt.yticks(pos, x_train.columns[sorted_idx][-20:])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Building the Keras model\n",
    "- simple architecture for a regression model\n",
    "- relu activation function\n",
    "- mean_squared_logarithmic_error is used as competition metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras.models import Sequential\\nfrom keras.layers.core import Dense\\n\\nmodel = Sequential()\\nmodel.add(Dense(1024, input_dim= x_train.shape[1], init='normal', activation='relu'))\\nmodel.add(Dense(256, init='normal', activation='relu'))\\nmodel.add(Dense(64, init='normal', activation='relu'))\\nmodel.add(Dense(16, init='normal', activation='relu'))\\nmodel.add(Dense(1, init='normal'))\\n\\nmodel.compile(loss='mean_squared_logarithmic_error', optimizer='adam')\\nmodel.fit(x_train, y_train, epochs=100, batch_size=1)\\n\\n#Save the model\\nfrom keras.models import load_model\\n\\nmodel.save('model_house_prices.h5')  # creates a HDF5 file 'my_model.h5'\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim= x_train.shape[1], init='normal', activation='relu'))\n",
    "model.add(Dense(256, init='normal', activation='relu'))\n",
    "model.add(Dense(64, init='normal', activation='relu'))\n",
    "model.add(Dense(16, init='normal', activation='relu'))\n",
    "model.add(Dense(1, init='normal'))\n",
    "\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=1)\n",
    "\n",
    "#Save the model\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('model_house_prices.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbest_estimator = [10000,None]\\n\\n\\nfor model in models:\\n    clf = StackingRegressor(regressors=models, meta_regressor=model)\\n    scores = cross_val_score(clf, x_train, y_train, cv=5,scoring=\\'neg_mean_squared_error\\')\\n    scores = np.sqrt(-scores)\\n    score = scores.mean()\\n    if  score < best_estimator[0]:\\n        best_estimator[0] = score\\n        best_estimator[1] = clf\\n    print(\"Accuracy: %0.3f (+/- %0.3f)\" % (score, scores.std() * 2))\\n\\n        \\nest = best_estimator[1]\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso,ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model1 = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05)\n",
    "model2 = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=3, max_features='sqrt',min_samples_leaf=15, min_samples_split=10, loss='huber')\n",
    "model3 = GradientBoostingRegressor(n_estimators=1000,max_depth=10)\n",
    "model4 = GradientBoostingRegressor(n_estimators=25,max_depth=50)\n",
    "model5 = GradientBoostingRegressor(n_estimators=3000,max_depth=2,max_features='log2')\n",
    "\n",
    "model6 = RandomForestRegressor(n_estimators = 100,max_features='auto',max_depth=100)\n",
    "model7 = RandomForestRegressor(n_estimators = 100,max_depth=10,min_samples_leaf=3)\n",
    "model8 = RandomForestRegressor(n_estimators = 100,max_depth=5,min_samples_leaf=2)\n",
    "model9 = RandomForestRegressor(n_estimators = 100,max_features='log2', max_depth=2)\n",
    "\n",
    "model10 = Ridge(random_state=1)\n",
    "model11 = Lasso(random_state=1)\n",
    "model12 = SVR(kernel='linear')\n",
    "model13 = SVR(kernel='rbf',max_iter=10000)\n",
    "\n",
    "model14 = ElasticNet(alpha = 0.0001, l1_ratio=1, max_iter=10000)\n",
    "model15 = ElasticNet(alpha =1 , l1_ratio=.01, max_iter=10000)\n",
    "model16 = LinearRegression()\n",
    "\n",
    "\n",
    "models = [model1,model2,model3,model4,model5,model6,model7,model8,model9,model10, model11,model12,model13,model14,model15,model16]\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# averaging version\n",
    "'''\n",
    "Final_labels = np.zeros([1459])\n",
    "for model in models:\n",
    "    model = model.fit(x_train, y_train)\n",
    "    Final_labels += np.exp(model.predict(x_test))\n",
    "Final_labels = Final_labels / float(18)\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "best_estimator = [10000,None]\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    clf = StackingRegressor(regressors=models, meta_regressor=model)\n",
    "    scores = cross_val_score(clf, x_train, y_train, cv=5,scoring='neg_mean_squared_error')\n",
    "    scores = np.sqrt(-scores)\n",
    "    score = scores.mean()\n",
    "    if  score < best_estimator[0]:\n",
    "        best_estimator[0] = score\n",
    "        best_estimator[1] = clf\n",
    "    print(\"Accuracy: %0.3f (+/- %0.3f)\" % (score, scores.std() * 2))\n",
    "\n",
    "        \n",
    "est = best_estimator[1]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost regressor Cross validation grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.model_selection import cross_val_score,GridSearchCV\\n\\nest = GradientBoostingRegressor(loss='huber')\\n\\n\\nparam_grid = [\\n  {'n_estimators': [3000],\\n   'learning_rate': [0.05, 0.01],\\n    'min_samples_leaf': [3, 6],\\n    'max_depth': [3, 5], \\n    'max_features': ['log2','auto'], \\n   'subsample' : [0.7,0.9] }\\n ]\\n\\ngs_cv = GridSearchCV(est, param_grid, scoring='neg_mean_squared_error', n_jobs=4).fit(x_train, y_train)\\n\\nest = gs_cv.best_estimator\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "\n",
    "est = GradientBoostingRegressor(loss='huber')\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "  {'n_estimators': [3000],\n",
    "   'learning_rate': [0.05, 0.01],\n",
    "    'min_samples_leaf': [3, 6],\n",
    "    'max_depth': [3, 5], \n",
    "    'max_features': ['log2','auto'], \n",
    "   'subsample' : [0.7,0.9] }\n",
    " ]\n",
    "\n",
    "gs_cv = GridSearchCV(est, param_grid, scoring='neg_mean_squared_error', n_jobs=4).fit(x_train, y_train)\n",
    "\n",
    "est = gs_cv.best_estimator\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
